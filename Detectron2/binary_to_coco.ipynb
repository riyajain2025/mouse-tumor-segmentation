{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8203216c-6074-41eb-a877-601afc0adb41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get data ready to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66810245-290a-41de-9ae4-51eb63db02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f705f13-af71-44b5-9d9e-aa94f54ecb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_to_array(folder_path):\n",
    "\n",
    "  image_array = []\n",
    "  # Get a sorted list of filenames\n",
    "  filenames = sorted(os.listdir(folder_path))\n",
    "  for filename in filenames:\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "      img_path = os.path.join(folder_path, filename)\n",
    "      img = cv2.imread(img_path)\n",
    "\n",
    "      if img is not None:\n",
    "        image_array.append(img)\n",
    "\n",
    "  return image_array\n",
    "\n",
    "def read_bin_files_to_array(folder_path):\n",
    "    bin_files = []\n",
    "    filenames = sorted(os.listdir(folder_path))\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.bin'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'rb') as file:\n",
    "                data = np.fromfile(file, dtype=np.float32)\n",
    "                bin_files.append(data)\n",
    "\n",
    "    return bin_files\n",
    "\n",
    "\n",
    "def split_images(image_array): \n",
    "\n",
    "    red_region_images = []\n",
    "    raw_images = [] \n",
    "\n",
    "    for image in image_array:\n",
    "        if image[25,100].sum() == 255*3 :\n",
    "            red_region_images.append(image)\n",
    "        else: \n",
    "            raw_images.append(image) \n",
    "            \n",
    "    return red_region_images, raw_images\n",
    "\n",
    "def split_train_val_test(images, masks):\n",
    "\n",
    "    train_images = []\n",
    "    train_masks = []\n",
    "    val_images = []\n",
    "    val_masks = []\n",
    "    test_images = []\n",
    "    test_masks = []\n",
    "\n",
    "    for i in range(len(images)): \n",
    "\n",
    "    # these numbers are made specifically for this dataset \n",
    "        \n",
    "        if i < 27: \n",
    "            train_images.append(images[i])\n",
    "            train_masks.append(masks[i])\n",
    "        elif i < 32:\n",
    "            val_images.append(images[i])\n",
    "            val_masks.append(masks[i])\n",
    "        else: \n",
    "            test_images.append(images[i])\n",
    "            test_masks.append(masks[i])\n",
    "\n",
    "    return train_images, train_masks, val_images, val_masks, test_images, test_masks\n",
    "\n",
    "def crop_raw_images(image_array): \n",
    "    \n",
    "    cropped_images = [] \n",
    "    \n",
    "    for i in range(len(image_array)): \n",
    "        \n",
    "        image = image_array[i]\n",
    "        \n",
    "        mask = np.zeros(image.shape, dtype=np.uint8)\n",
    "        mask = cv2.circle(mask, (320, 240), 200, (255,255,255), -1)\n",
    "\n",
    "        res = cv2.bitwise_and(image, mask)\n",
    "        res[mask==0] = 255\n",
    "        \n",
    "        cropped_images.append(res)\n",
    "\n",
    "    return cropped_images\n",
    "\n",
    "def crop_masks(image_array):\n",
    "    cropped_images = []\n",
    "\n",
    "    for i in range(len(image_array)): \n",
    "        image = image_array[i]\n",
    "        \n",
    "        mask = np.zeros(image.shape, dtype=np.uint8)\n",
    "        mask = cv2.circle(mask, (288, 307), 200, (255,255,255), -1)\n",
    "\n",
    "        res = cv2.bitwise_and(image, mask)\n",
    "        res[mask==0] = 255\n",
    "        \n",
    "        cropped_images.append(res)\n",
    "\n",
    "    return cropped_images\n",
    "\n",
    "def add_padding(image_array, amt_x, amt_y): \n",
    "    \n",
    "    padded_images = []\n",
    "    \n",
    "    for image in image_array: \n",
    "\n",
    "        padded_image = cv2.copyMakeBorder(\n",
    "            image,\n",
    "            amt_y,\n",
    "            amt_y,\n",
    "            amt_x,\n",
    "            amt_x,\n",
    "            cv2.BORDER_CONSTANT,\n",
    "            value=(255,255,255)\n",
    "        )\n",
    "        \n",
    "        padded_images.append(padded_image)\n",
    "        \n",
    "    return padded_images\n",
    "\n",
    "def zoom_at(image_array, zoom, coord=None):\n",
    "    \n",
    "    zoomed_array = []\n",
    "    \n",
    "    for img in image_array: \n",
    "        \n",
    "        h, w, _ = [ zoom * i for i in img.shape ]\n",
    "\n",
    "        if coord is None: cx, cy = w/2, h/2\n",
    "        else: cx, cy = [ zoom*c for c in coord ]\n",
    "\n",
    "        img = cv2.resize( img, (0, 0), fx=zoom, fy=zoom)\n",
    "        img = img[ int(round(cy - h/zoom * .5)) : int(round(cy + h/zoom * .5)),\n",
    "                   int(round(cx - w/zoom * .5)) : int(round(cx + w/zoom * .5)),\n",
    "                   : ]\n",
    "        zoomed_array.append(img)\n",
    "    \n",
    "    return zoomed_array\n",
    "\n",
    "\n",
    "def create_binary_masks(image_array):\n",
    "    binary_masks = []\n",
    "    \n",
    "    for image in image_array:\n",
    "        # Ensure image is in BGR format (convert if necessary)\n",
    "        if image.ndim == 2:\n",
    "            # Convert grayscale to BGR color (assuming gray image)\n",
    "            image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        elif image.shape[2] != 3:\n",
    "            raise ValueError(\"Input image must have 3 channels (BGR format).\")\n",
    "        else:\n",
    "            image_color = image\n",
    "        \n",
    "        # Convert BGR to HSV\n",
    "        hsv = cv2.cvtColor(image_color, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define lower and upper bounds for red color in HSV\n",
    "        lower_red = np.array([0, 150, 115])\n",
    "        upper_red = np.array([255, 255, 255])\n",
    "\n",
    "        # Create mask using inRange function\n",
    "        mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "        # Apply bitwise AND operation using color image\n",
    "        res = cv2.bitwise_and(image_color, image_color, mask=mask)\n",
    "        \n",
    "        binary_masks.append(mask)\n",
    "        \n",
    "    return binary_masks\n",
    "\n",
    "def crop_images(image_array): \n",
    "    \n",
    "    cropped_images = []\n",
    "    \n",
    "    for i in range(len(image_array) -1): \n",
    "        \n",
    "        image = image_array[i]\n",
    "        \n",
    "        image_height, image_width = image.shape[:2]\n",
    "        \n",
    "        # Bounding box dimensions\n",
    "        box_width, box_height = 256, 256\n",
    "\n",
    "        x_top_left = (image_width - box_width) // 2\n",
    "        y_top_left = (image_height - box_height) // 2\n",
    "        x_bottom_right = x_top_left + box_width\n",
    "        y_bottom_right = y_top_left + box_height\n",
    "        \n",
    "        cropped_image = image[y_top_left:y_bottom_right, x_top_left:x_bottom_right]\n",
    "        cropped_images.append(cropped_image)\n",
    "                              \n",
    "    return cropped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e569de4-3886-41fd-b96f-c5c5bdd08bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images\n",
    "folder_path_training = '../data/invotive_data_split/train'\n",
    "train_images = read_images_to_array(folder_path_training)\n",
    "folder_path_val = '../data/invotive_data_split/val'\n",
    "val_images = read_images_to_array(folder_path_val)\n",
    "\n",
    "train_masks, train_images = split_images(train_images) \n",
    "val_masks, val_images = split_images(val_images) \n",
    "\n",
    "train_images = crop_raw_images(train_images)\n",
    "train_images = add_padding(train_images, 0, 67)\n",
    "train_masks = crop_masks(train_masks)\n",
    "train_masks = add_padding(train_masks, 31, 0)\n",
    "train_masks = zoom_at(train_masks, 1.156, coord=None)\n",
    "train_masks = create_binary_masks(train_masks)\n",
    "\n",
    "val_images = crop_raw_images(val_images)\n",
    "val_images = add_padding(val_images, 0, 67)\n",
    "val_masks = crop_masks(val_masks)\n",
    "val_masks = add_padding(val_masks, 31, 0)\n",
    "val_masks = zoom_at(val_masks, 1.156, coord=None)\n",
    "val_masks = create_binary_masks(val_masks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0737505-eeb8-4524-acff-1548175a892c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now convert the binary masks to coco json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf36cd-2a44-411c-a388-0c014dc3f6d2",
   "metadata": {},
   "source": [
    "### Only run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b307860-cc71-4168-b505-5d09dc9ebc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image_array, folder_path, base_filename='image'):\n",
    "    \n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Iterate through the image array and save each image\n",
    "    for idx, img in enumerate(image_array):\n",
    "        # Construct the filename\n",
    "        filename = f\"{base_filename}_{idx+1}.png\"\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Save the image\n",
    "        cv2.imwrite(file_path, img)\n",
    "\n",
    "    print(f\"Images have been saved to {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98da9cd2-a4d0-49f1-89a9-245c8228b6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been saved to ../data/coco_json/invotive_data/val/masks/Tumor\n",
      "Images have been saved to ../data/coco_json/invotive_data/val/images\n",
      "Images have been saved to ../data/coco_json/invotive_data/train/masks/Tumor\n",
      "Images have been saved to ../data/coco_json/invotive_data/train/images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_images(val_masks, '../data/coco_json/invotive_data/val/masks/Tumor', base_filename='image')\n",
    "save_images(val_images, '../data/coco_json/invotive_data/val/images', base_filename='image')\n",
    "\n",
    "save_images(train_masks, '../data/coco_json/invotive_data/train/masks/Tumor', base_filename='image')\n",
    "save_images(train_images, '../data/coco_json/invotive_data/train/images', base_filename='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ff965b9-a870-41aa-800e-008db0f34411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "category_ids = {\n",
    "    \"Tumor\": 0\n",
    "}\n",
    "\n",
    "MASK_EXT = 'png'\n",
    "ORIGINAL_EXT = 'png'\n",
    "image_id = 0\n",
    "annotation_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24522dd0-e650-4111-bda3-5bdc257ebe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_annotations_info(maskpath):\n",
    "    global image_id, annotation_id\n",
    "    annotations = []\n",
    "    images = []\n",
    "\n",
    "    for category in category_ids.keys():\n",
    "        for mask_image in glob.glob(os.path.join(maskpath, category, f'*.{MASK_EXT}')):\n",
    "            original_file_name = f'{os.path.basename(mask_image).split(\".\")[0]}.{ORIGINAL_EXT}'\n",
    "            mask_image_open = cv2.imread(mask_image)\n",
    "            \n",
    "            height, width, _ = mask_image_open.shape\n",
    "\n",
    "            if original_file_name not in map(lambda img: img['file_name'], images):\n",
    "                image = {\n",
    "                    \"id\": image_id + 1,\n",
    "                    \"width\": width,\n",
    "                    \"height\": height,\n",
    "                    \"file_name\": original_file_name,\n",
    "                }\n",
    "                images.append(image)\n",
    "                image_id += 1\n",
    "            else:\n",
    "                image = [element for element in images if element['file_name'] == original_file_name][0]\n",
    "\n",
    "            gray = cv2.cvtColor(mask_image_open, cv2.COLOR_BGR2GRAY)\n",
    "            _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "            for contour in contours:\n",
    "                bbox = cv2.boundingRect(contour)\n",
    "                area = cv2.contourArea(contour)\n",
    "                segmentation = contour.flatten().tolist()\n",
    "\n",
    "                annotation = {\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"id\": annotation_id,\n",
    "                    \"image_id\": image['id'],\n",
    "                    \"category_id\": category_ids[category],\n",
    "                    \"bbox\": bbox,\n",
    "                    \"area\": area,\n",
    "                    \"segmentation\": [segmentation],\n",
    "                }\n",
    "\n",
    "                if area > 0:\n",
    "                    annotations.append(annotation)\n",
    "                    annotation_id += 1\n",
    "\n",
    "    return images, annotations, annotation_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7a2fb33-4c55-4a9e-a42d-240793ea7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_masks(mask_path, dest_json):\n",
    "    global image_id, annotation_id\n",
    "    image_id = 0\n",
    "    annotation_id = 0\n",
    "\n",
    "    coco_format = {\n",
    "        \"info\": {},\n",
    "        \"licenses\": [],\n",
    "        \"images\": [],\n",
    "        \"categories\": [{\"id\": value, \"name\": key, \"supercategory\": key} for key, value in category_ids.items()],\n",
    "        \"annotations\": [],\n",
    "    }\n",
    "\n",
    "    coco_format[\"images\"], coco_format[\"annotations\"], annotation_cnt = images_annotations_info(mask_path)\n",
    "\n",
    "    with open(dest_json, \"w\") as outfile:\n",
    "        json.dump(coco_format, outfile, sort_keys=True, indent=4)\n",
    "\n",
    "    print(\"Created %d annotations for images in folder: %s\" % (annotation_cnt, mask_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65bca3e3-d15a-47d0-a81c-6e923b1739b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 45 annotations for images in folder: ../data/coco_json/invotive_data/train/masks\n"
     ]
    }
   ],
   "source": [
    "train_mask_path = \"../data/coco_json/invotive_data/train/masks\"\n",
    "train_json_path = \"../data/coco_json/invotive_data/train/images/train.json\"\n",
    "\n",
    "val_mask_path = \"../data/coco_json/invotive_data/val/masks\"\n",
    "val_json_path = \"../data/coco_json/invotive_data/val/images/train.json\"\n",
    "\n",
    "process_masks(train_mask_path, train_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ee7ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 39 annotations for images in folder: ../data/coco_json/invotive_data/val/masks\n"
     ]
    }
   ],
   "source": [
    "process_masks(val_mask_path, val_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d8418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
